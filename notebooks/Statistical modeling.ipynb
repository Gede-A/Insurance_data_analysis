{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9184722b-183a-4d24-b9ae-042874612cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UnderwrittenCoverID  PolicyID     TransactionMonth  IsVATRegistered  \\\n",
      "0               145249     12827  2015-03-01 00:00:00             True   \n",
      "\n",
      "  Citizenship          LegalType Title Language                 Bank  \\\n",
      "0              Close Corporation    Mr  English  First National Bank   \n",
      "\n",
      "       AccountType  ...         ExcessSelected CoverCategory   CoverType  \\\n",
      "0  Current account  ...  Mobility - Windscreen    Windscreen  Windscreen   \n",
      "\n",
      "             CoverGroup              Section                          Product  \\\n",
      "0  Comprehensive - Taxi  Motor Comprehensive  Mobility Metered Taxis: Monthly   \n",
      "\n",
      "  StatutoryClass StatutoryRiskType  TotalPremium TotalClaims  \n",
      "0     Commercial     IFRS Constant     21.929825         0.0  \n",
      "\n",
      "[1 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the column names\n",
    "columns = [\n",
    "    \"UnderwrittenCoverID\", \"PolicyID\", \"TransactionMonth\", \"IsVATRegistered\", \"Citizenship\", \"LegalType\", \n",
    "    \"Title\", \"Language\", \"Bank\", \"AccountType\", \"MaritalStatus\", \"Gender\", \"Country\", \"Province\", \"PostalCode\", \n",
    "    \"MainCrestaZone\", \"SubCrestaZone\", \"ItemType\", \"mmcode\", \"VehicleType\", \"RegistrationYear\", \"make\", \"Model\", \n",
    "    \"Cylinders\", \"cubiccapacity\", \"kilowatts\", \"bodytype\", \"NumberOfDoors\", \"VehicleIntroDate\", \n",
    "    \"CustomValueEstimate\", \"AlarmImmobiliser\", \"TrackingDevice\", \"CapitalOutstanding\", \"NewVehicle\", \"WrittenOff\", \n",
    "    \"Rebuilt\", \"Converted\", \"CrossBorder\", \"NumberOfVehiclesInFleet\", \"SumInsured\", \"TermFrequency\", \n",
    "    \"CalculatedPremiumPerTerm\", \"ExcessSelected\", \"CoverCategory\", \"CoverType\", \"CoverGroup\", \"Section\", \n",
    "    \"Product\", \"StatutoryClass\", \"StatutoryRiskType\", \"TotalPremium\", \"TotalClaims\"\n",
    "]\n",
    "\n",
    "# Read the file directly (adjust the path as necessary)\n",
    "df = pd.read_csv(r'..\\MachineLearningRating.txt', sep='|', header=None, names=columns, low_memory=False)\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(df.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8a6a1-0fe2-48c0-b1d8-e7555cf3be12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "484dd62f-6bdb-453b-b1c7-6f241b2fdfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank                        145961\n",
      "AccountType                  40232\n",
      "MaritalStatus                 8259\n",
      "Gender                        9536\n",
      "mmcode                         552\n",
      "VehicleType                    552\n",
      "make                           552\n",
      "Model                          552\n",
      "Cylinders                      552\n",
      "cubiccapacity                  552\n",
      "kilowatts                      552\n",
      "bodytype                       552\n",
      "NumberOfDoors                  552\n",
      "VehicleIntroDate               552\n",
      "CustomValueEstimate         779642\n",
      "CapitalOutstanding               2\n",
      "NewVehicle                  153295\n",
      "WrittenOff                  641901\n",
      "Rebuilt                     641901\n",
      "Converted                   641901\n",
      "CrossBorder                 999400\n",
      "NumberOfVehiclesInFleet    1000098\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "missing_data = df.isnull().sum()\n",
    "print(missing_data[missing_data > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a78f18-c80b-44c3-9b4e-7878746dad27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CraftSoft\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1231: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# Impute numerical data with median\n",
    "numerical_columns = df.select_dtypes(include='number')\n",
    "for column in numerical_columns:\n",
    "    df[column] = df[column].fillna(df[column].median())\n",
    "\n",
    "# Impute categorical data with mode\n",
    "categorical_columns = df.select_dtypes(include='object')\n",
    "for category_column in categorical_columns:\n",
    "    df[category_column] = df[category_column].fillna(df[category_column].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2000e087-428f-4ddd-bd3d-e124dca7759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_year = datetime.now().year\n",
    "df['VehicleAge'] = current_year - df['RegistrationYear']\n",
    "df['VehicleAgeGroup'] = pd.cut(df['VehicleAge'], bins=[0, 1, 5, 10, 100], labels=['New', '1-5 years', '6-10 years', 'Over 10 years'])\n",
    "df['PremiumToClaimsRatio'] = df['TotalPremium'] / df['TotalClaims']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4a8d00f-59ba-4c2c-b1c1-1af483152b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'make', 'Model', 'bodytype', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f0325c-11cc-47ff-87a5-0a8f7f826950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['IsVATRegistered'] = le.fit_transform(df['IsVATRegistered'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40ce6f-08aa-4554-a23a-53a03d49d5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame Columns: Index(['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth',\n",
      "       'IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language',\n",
      "       'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province',\n",
      "       'PostalCode', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'mmcode',\n",
      "       'VehicleType', 'RegistrationYear', 'make', 'Model', 'Cylinders',\n",
      "       'cubiccapacity', 'kilowatts', 'bodytype', 'NumberOfDoors',\n",
      "       'VehicleIntroDate', 'CustomValueEstimate', 'AlarmImmobiliser',\n",
      "       'TrackingDevice', 'CapitalOutstanding', 'NewVehicle', 'WrittenOff',\n",
      "       'Rebuilt', 'Converted', 'CrossBorder', 'NumberOfVehiclesInFleet',\n",
      "       'SumInsured', 'TermFrequency', 'CalculatedPremiumPerTerm',\n",
      "       'ExcessSelected', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section',\n",
      "       'Product', 'StatutoryClass', 'StatutoryRiskType', 'TotalPremium',\n",
      "       'TotalClaims'],\n",
      "      dtype='object')\n",
      "Categorical Columns Present: ['Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'make', 'Model', 'bodytype', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType']\n",
      "Columns to encode: ['Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'make', 'Model', 'bodytype', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType']\n",
      "Columns after encoding: Index(['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth',\n",
      "       'IsVATRegistered', 'PostalCode', 'mmcode', 'VehicleType',\n",
      "       'RegistrationYear', 'Cylinders', 'cubiccapacity',\n",
      "       ...\n",
      "       'Section_Motor Comprehensive', 'Section_Optional Extended Covers',\n",
      "       'Section_Standalone passenger liability',\n",
      "       'Section_Third party or third party, fire and theft only',\n",
      "       'Product_Bridge Taxi Finance: Monthly',\n",
      "       'Product_Mobility Commercial Cover: Monthly',\n",
      "       'Product_Mobility Metered Taxis: Monthly',\n",
      "       'Product_Standalone Passenger Liability', 'StatutoryClass_Commercial',\n",
      "       'StatutoryRiskType_IFRS Constant'],\n",
      "      dtype='object', length=682)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Load your DataFrame (replace this with your actual data loading method)\n",
    "# df = pd.read_csv('your_file.csv')  # Example of loading data\n",
    "\n",
    "# Check the columns in your DataFrame\n",
    "print(\"Original DataFrame Columns:\", df.columns)\n",
    "\n",
    "# Data Preparation\n",
    "# Fill missing values\n",
    "# Impute numerical data with median\n",
    "# numerical_columns = df.select_dtypes(include='number')\n",
    "# for column in numerical_columns:\n",
    "#     df[column] = df[column].fillna(df[column].median())\n",
    "\n",
    "# # Impute categorical data with mode\n",
    "# categorical_columns = df.select_dtypes(include='object')\n",
    "# for category_column in categorical_columns:\n",
    "#     df[category_column] = df[category_column].fillna(df[category_column].mode()[0])\n",
    "\n",
    "if 'RegistrationYear' in df.columns:\n",
    "    df['RegistrationYear'] = df['RegistrationYear'].fillna(df['RegistrationYear'].median())\n",
    "else:\n",
    "    print(\"Column 'RegistrationYear' not found in DataFrame\")\n",
    "\n",
    "if 'Bank' in df.columns:\n",
    "    df['Bank'] = df['Bank'].fillna(df['Bank'].mode()[0])\n",
    "else:\n",
    "    print(\"Column 'Bank' not found in DataFrame\")\n",
    "\n",
    "# Feature Engineering and Encoding\n",
    "categorical_columns = [\n",
    "    'Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType',\n",
    "    'MaritalStatus', 'Gender', 'Country', 'Province', 'MainCrestaZone',\n",
    "    'SubCrestaZone', 'ItemType', 'make', 'Model', 'bodytype', 'CoverCategory',\n",
    "    'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType'\n",
    "]\n",
    "\n",
    "# Check which categorical columns are present in the DataFrame\n",
    "existing_categorical_columns = [col for col in categorical_columns if col in df.columns]\n",
    "print(\"Categorical Columns Present:\", existing_categorical_columns)\n",
    "\n",
    "# Create a list of columns to exclude from encoding (including the target variable)\n",
    "exclude_columns = ['TotalPremium', 'TotalClaims']\n",
    "\n",
    "# Ensure target variable is not encoded\n",
    "columns_to_encode = [col for col in existing_categorical_columns if col not in exclude_columns]\n",
    "\n",
    "print(\"Columns to encode:\", columns_to_encode)\n",
    "\n",
    "if columns_to_encode:\n",
    "    # Encode categorical columns if they exist\n",
    "    df_encoded = pd.get_dummies(df, columns=columns_to_encode, drop_first=False)\n",
    "else:\n",
    "    print(\"No categorical columns found to encode.\")\n",
    "    df_encoded = df.copy()  # If no categorical columns, use the original DataFrame\n",
    "\n",
    "# Check the columns after encoding\n",
    "print(\"Columns after encoding:\", df_encoded.columns)\n",
    "\n",
    "# Ensure the target variable 'TotalPremium' is still present\n",
    "if 'TotalPremium' in df_encoded.columns:\n",
    "    X = df_encoded.drop(['TotalPremium', 'TotalClaims'], axis=1, errors='ignore')\n",
    "    y = df_encoded['TotalPremium']\n",
    "else:\n",
    "    raise ValueError(\"Target variable 'TotalPremium' not found in DataFrame\")\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle NaN values in training data\n",
    "X_train = X_train.fillna(X_train.mean())\n",
    "X_test = X_test.fillna(X_train.mean())  # Ensure the test set has the same NaN handling as the training set\n",
    "y_train = y_train.fillna(y_train.mean())\n",
    "y_test = y_test.fillna(y_train.mean())  # Ensure the test set has the same NaN handling as the training set\n",
    "\n",
    "# Modeling Techniques\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model_name, y_test, predictions):\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    print(f\"\\n{model_name} Evaluation Metrics:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"R² Score: {r2}\")\n",
    "\n",
    "# 1. Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "evaluate_model(\"Linear Regression\", y_test, lr_predictions)\n",
    "\n",
    "# 2. Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor()\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "evaluate_model(\"Decision Tree Regressor\", y_test, dt_predictions)\n",
    "\n",
    "# 3. Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "evaluate_model(\"Random Forest Regressor\", y_test, rf_predictions)\n",
    "\n",
    "# 4. XGBoost Regressor\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "evaluate_model(\"XGBoost Regressor\", y_test, xgb_predictions)\n",
    "\n",
    "# Feature Importance Analysis (for Random Forest and XGBoost)\n",
    "if hasattr(rf_model, 'feature_importances_'):\n",
    "    importances_rf = rf_model.feature_importances_\n",
    "    print(\"\\nFeature Importances (Random Forest):\")\n",
    "    for feature, importance in zip(X.columns, importances_rf):\n",
    "        print(f\"{feature}: {importance}\")\n",
    "\n",
    "if hasattr(xgb_model, 'feature_importances_'):\n",
    "    importances_xgb = xgb_model.feature_importances_\n",
    "    print(\"\\nFeature Importances (XGBoost):\")\n",
    "    for feature, importance in zip(X.columns, importances_xgb):\n",
    "        print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a1bd88-1a40-45c6-8c0b-256479616c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Check the columns in your DataFrame\n",
    "print(\"Original DataFrame Columns:\", df.columns)\n",
    "\n",
    "# Data Preparation\n",
    "# Fill missing values\n",
    "# Impute numerical data with median\n",
    "numerical_columns = df.select_dtypes(include='number')\n",
    "for column in numerical_columns:\n",
    "    df[column] = df[column].fillna(df[column].median())\n",
    "\n",
    "# Impute categorical data with mode\n",
    "categorical_columns = df.select_dtypes(include='object')\n",
    "for category_column in categorical_columns:\n",
    "    df[category_column] = df[category_column].fillna(df[category_column].mode()[0])\n",
    "# if 'RegistrationYear' in df.columns:\n",
    "#     df['RegistrationYear'] = df['RegistrationYear'].fillna(df['RegistrationYear'].median())\n",
    "# else:\n",
    "#     print(\"Column 'RegistrationYear' not found in DataFrame\")\n",
    "\n",
    "# if 'Bank' in df.columns:\n",
    "#     df['Bank'] = df['Bank'].fillna(df['Bank'].mode()[0])\n",
    "# else:\n",
    "#     print(\"Column 'Bank' not found in DataFrame\")\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_columns = [\n",
    "    'Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType',\n",
    "    'MaritalStatus', 'Gender', 'Country', 'Province', 'MainCrestaZone',\n",
    "    'SubCrestaZone', 'ItemType', 'make', 'Model', 'bodytype', 'CoverCategory',\n",
    "    'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType'\n",
    "]\n",
    "\n",
    "# Check which categorical columns are present in the DataFrame\n",
    "existing_categorical_columns = [col for col in categorical_columns if col in df.columns]\n",
    "print(\"Categorical Columns Present:\", existing_categorical_columns)\n",
    "\n",
    "# Use label encoding for columns with high cardinality and one-hot encoding for others\n",
    "high_cardinality_columns = [col for col in existing_categorical_columns if df[col].nunique() > 10]\n",
    "low_cardinality_columns = [col for col in existing_categorical_columns if col not in high_cardinality_columns]\n",
    "\n",
    "# Label Encoding for high cardinality columns\n",
    "label_encoder = LabelEncoder()\n",
    "for col in high_cardinality_columns:\n",
    "    df[col] = label_encoder.fit_transform(df[col].astype(str))\n",
    "\n",
    "# One-Hot Encoding for low cardinality columns\n",
    "if low_cardinality_columns:\n",
    "    df = pd.get_dummies(df, columns=low_cardinality_columns, drop_first=True)\n",
    "\n",
    "# Ensure the target variable 'TotalPremium' is still present\n",
    "if 'TotalPremium' in df.columns:\n",
    "    X = df.drop(['TotalPremium', 'TotalClaims'], axis=1, errors='ignore')\n",
    "    y = df['TotalPremium']\n",
    "else:\n",
    "    raise ValueError(\"Target variable 'TotalPremium' not found in DataFrame\")\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle NaN values in training data\n",
    "X_train = X_train.fillna(X_train.mean())\n",
    "X_test = X_test.fillna(X_train.mean())  # Ensure the test set has the same NaN handling as the training set\n",
    "y_train = y_train.fillna(y_train.mean())\n",
    "y_test = y_test.fillna(y_train.mean())  # Ensure the test set has the same NaN handling as the training set\n",
    "\n",
    "# Modeling Techniques\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost Regressor\": XGBRegressor()\n",
    "}\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model_name, y_test, predictions):\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    print(f\"\\n{model_name} Evaluation Metrics:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"R² Score: {r2}\")\n",
    "\n",
    "# Training and evaluating each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    evaluate_model(model_name, y_test, predictions)\n",
    "\n",
    "# Feature Importance Analysis (for Random Forest and XGBoost)\n",
    "for model_name, model in models.items():\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        print(f\"\\nFeature Importances ({model_name}):\")\n",
    "        for feature, importance in zip(X.columns, importances):\n",
    "            print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a1494-3965-4b7d-bfa0-612001e60468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns Present: ['Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'make', 'Model', 'bodytype', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType']\n",
      "Columns to encode: ['Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'make', 'Model', 'bodytype', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType']\n",
      "Columns after encoding: Index(['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth',\n",
      "       'IsVATRegistered', 'PostalCode', 'mmcode', 'VehicleType',\n",
      "       'RegistrationYear', 'Cylinders', 'cubiccapacity',\n",
      "       ...\n",
      "       'Section_Motor Comprehensive', 'Section_Optional Extended Covers',\n",
      "       'Section_Standalone passenger liability',\n",
      "       'Section_Third party or third party, fire and theft only',\n",
      "       'Product_Bridge Taxi Finance: Monthly',\n",
      "       'Product_Mobility Commercial Cover: Monthly',\n",
      "       'Product_Mobility Metered Taxis: Monthly',\n",
      "       'Product_Standalone Passenger Liability', 'StatutoryClass_Commercial',\n",
      "       'StatutoryRiskType_IFRS Constant'],\n",
      "      dtype='object', length=682)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# df = pd.read_csv('your_file.csv')  # Example of loading data\n",
    "\n",
    "# Data Preparation\n",
    "# Fill missing values\n",
    "if 'RegistrationYear' in df.columns:\n",
    "    df['RegistrationYear'] = df['RegistrationYear'].fillna(df['RegistrationYear'].median())\n",
    "else:\n",
    "    print(\"Column 'RegistrationYear' not found in DataFrame\")\n",
    "\n",
    "if 'Bank' in df.columns:\n",
    "    df['Bank'] = df['Bank'].fillna(df['Bank'].mode()[0])\n",
    "else:\n",
    "    print(\"Column 'Bank' not found in DataFrame\")\n",
    "\n",
    "# Feature Engineering and Encoding\n",
    "categorical_columns = [\n",
    "    'Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType',\n",
    "    'MaritalStatus', 'Gender', 'Country', 'Province', 'MainCrestaZone',\n",
    "    'SubCrestaZone', 'ItemType', 'make', 'Model', 'bodytype', 'CoverCategory',\n",
    "    'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType'\n",
    "]\n",
    "\n",
    "# Check which categorical columns are present in the DataFrame\n",
    "existing_categorical_columns = [col for col in categorical_columns if col in df.columns]\n",
    "print(\"Categorical Columns Present:\", existing_categorical_columns)\n",
    "\n",
    "# Create a list of columns to exclude from encoding (including the target variable)\n",
    "exclude_columns = ['TotalPremium', 'TotalClaims']\n",
    "\n",
    "# Ensure target variable is not encoded\n",
    "columns_to_encode = [col for col in existing_categorical_columns if col not in exclude_columns]\n",
    "print(\"Columns to encode:\", columns_to_encode)\n",
    "\n",
    "if columns_to_encode:\n",
    "    # Encode categorical columns if they exist\n",
    "    df_encoded = pd.get_dummies(df, columns=columns_to_encode, drop_first=False)\n",
    "else:\n",
    "    print(\"No categorical columns found to encode.\")\n",
    "    df_encoded = df.copy()  # If no categorical columns, use the original DataFrame\n",
    "\n",
    "# Check the columns after encoding\n",
    "print(\"Columns after encoding:\", df_encoded.columns)\n",
    "\n",
    "# Ensure the target variable 'TotalPremium' is still present\n",
    "if 'TotalPremium' in df_encoded.columns:\n",
    "    X = df_encoded.drop(['TotalPremium', 'TotalClaims'], axis=1, errors='ignore')\n",
    "    y = df_encoded['TotalPremium']\n",
    "else:\n",
    "    raise ValueError(\"Target variable 'TotalPremium' not found in DataFrame\")\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle NaN values in training data\n",
    "X_train = X_train.fillna(X_train.mean())\n",
    "X_test = X_test.fillna(X_train.mean())  # Ensure the test set has the same NaN handling as the training set\n",
    "y_train = y_train.fillna(y_train.mean())\n",
    "y_test = y_test.fillna(y_train.mean())  # Ensure the test set has the same NaN handling as the training set\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model_name, y_test, predictions):\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    print(f\"\\n{model_name} Evaluation Metrics:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"R² Score: {r2}\")\n",
    "\n",
    "# 1. Linear Regression\n",
    "try:\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    lr_predictions = lr_model.predict(X_test)\n",
    "    evaluate_model(\"Linear Regression\", y_test, lr_predictions)\n",
    "except Exception as e:\n",
    "    print(f\"Linear Regression failed: {e}\")\n",
    "\n",
    "# 2. Decision Tree Regressor\n",
    "try:\n",
    "    dt_model = DecisionTreeRegressor()\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    dt_predictions = dt_model.predict(X_test)\n",
    "    evaluate_model(\"Decision Tree Regressor\", y_test, dt_predictions)\n",
    "except Exception as e:\n",
    "    print(f\"Decision Tree Regressor failed: {e}\")\n",
    "\n",
    "# 3. Random Forest Regressor\n",
    "try:\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_predictions = rf_model.predict(X_test)\n",
    "    evaluate_model(\"Random Forest Regressor\", y_test, rf_predictions)\n",
    "except Exception as e:\n",
    "    print(f\"Random Forest Regressor failed: {e}\")\n",
    "\n",
    "# 4. XGBoost Regressor\n",
    "try:\n",
    "    xgb_model = XGBRegressor()\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_predictions = xgb_model.predict(X_test)\n",
    "    evaluate_model(\"XGBoost Regressor\", y_test, xgb_predictions)\n",
    "except Exception as e:\n",
    "    print(f\"XGBoost Regressor failed: {e}\")\n",
    "\n",
    "# Feature Importance Analysis (for Random Forest and XGBoost)\n",
    "if hasattr(rf_model, 'feature_importances_'):\n",
    "    importances_rf = rf_model.feature_importances_\n",
    "    print(\"\\nFeature Importances (Random Forest):\")\n",
    "    for feature, importance in zip(X.columns, importances_rf):\n",
    "        print(f\"{feature}: {importance}\")\n",
    "\n",
    "if hasattr(xgb_model, 'feature_importances_'):\n",
    "    importances_xgb = xgb_model.feature_importances_\n",
    "    print(\"\\nFeature Importances (XGBoost):\")\n",
    "    for feature, importance in zip(X.columns, importances_xgb):\n",
    "        print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0502c-e89c-40bb-9107-be09b45e1002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns Present: ['Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'make', 'Model', 'bodytype', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType']\n",
      "Columns to encode: ['Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'make', 'Model', 'bodytype', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType']\n",
      "Columns after encoding: Index(['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth',\n",
      "       'IsVATRegistered', 'PostalCode', 'mmcode', 'VehicleType',\n",
      "       'RegistrationYear', 'Cylinders', 'cubiccapacity',\n",
      "       ...\n",
      "       'Section_Motor Comprehensive', 'Section_Optional Extended Covers',\n",
      "       'Section_Standalone passenger liability',\n",
      "       'Section_Third party or third party, fire and theft only',\n",
      "       'Product_Bridge Taxi Finance: Monthly',\n",
      "       'Product_Mobility Commercial Cover: Monthly',\n",
      "       'Product_Mobility Metered Taxis: Monthly',\n",
      "       'Product_Standalone Passenger Liability', 'StatutoryClass_Commercial',\n",
      "       'StatutoryRiskType_IFRS Constant'],\n",
      "      dtype='object', length=682)\n",
      "Training Data Shape: (800078, 680)\n",
      "Test Data Shape: (200020, 680)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Load your DataFrame (replace this with your actual data loading method)\n",
    "# df = pd.read_csv('your_file.csv')  # Example of loading data\n",
    "\n",
    "# Data Preparation\n",
    "if 'RegistrationYear' in df.columns:\n",
    "    df['RegistrationYear'] = df['RegistrationYear'].fillna(df['RegistrationYear'].median())\n",
    "else:\n",
    "    print(\"Column 'RegistrationYear' not found in DataFrame\")\n",
    "\n",
    "if 'Bank' in df.columns:\n",
    "    df['Bank'] = df['Bank'].fillna(df['Bank'].mode()[0])\n",
    "else:\n",
    "    print(\"Column 'Bank' not found in DataFrame\")\n",
    "\n",
    "# Feature Engineering and Encoding\n",
    "categorical_columns = [\n",
    "    'Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType',\n",
    "    'MaritalStatus', 'Gender', 'Country', 'Province', 'MainCrestaZone',\n",
    "    'SubCrestaZone', 'ItemType', 'make', 'Model', 'bodytype', 'CoverCategory',\n",
    "    'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType'\n",
    "]\n",
    "\n",
    "# Check which categorical columns are present in the DataFrame\n",
    "existing_categorical_columns = [col for col in categorical_columns if col in df.columns]\n",
    "print(\"Categorical Columns Present:\", existing_categorical_columns)\n",
    "\n",
    "# Create a list of columns to exclude from encoding (including the target variable)\n",
    "exclude_columns = ['TotalPremium', 'TotalClaims']\n",
    "\n",
    "# Ensure target variable is not encoded\n",
    "columns_to_encode = [col for col in existing_categorical_columns if col not in exclude_columns]\n",
    "\n",
    "print(\"Columns to encode:\", columns_to_encode)\n",
    "\n",
    "if columns_to_encode:\n",
    "    df_encoded = pd.get_dummies(df, columns=columns_to_encode, drop_first=False)\n",
    "else:\n",
    "    print(\"No categorical columns found to encode.\")\n",
    "    df_encoded = df.copy()  # If no categorical columns, use the original DataFrame\n",
    "\n",
    "# Check the columns after encoding\n",
    "print(\"Columns after encoding:\", df_encoded.columns)\n",
    "\n",
    "# Ensure the target variable 'TotalPremium' is still present\n",
    "if 'TotalPremium' in df_encoded.columns:\n",
    "    X = df_encoded.drop(['TotalPremium', 'TotalClaims'], axis=1, errors='ignore')\n",
    "    y = df_encoded['TotalPremium']\n",
    "else:\n",
    "    raise ValueError(\"Target variable 'TotalPremium' not found in DataFrame\")\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Test Data Shape:\", X_test.shape)\n",
    "\n",
    "# Handle NaN values in training data\n",
    "X_train = X_train.fillna(X_train.mean())\n",
    "X_test = X_test.fillna(X_train.mean())  # Ensure the test set has the same NaN handling as the training set\n",
    "y_train = y_train.fillna(y_train.mean())\n",
    "y_test = y_test.fillna(y_train.mean())  # Ensure the test set has the same NaN handling as the training set\n",
    "\n",
    "# Modeling Techniques\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model_name, y_test, predictions):\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    print(f\"\\n{model_name} Evaluation Metrics:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"R² Score: {r2}\")\n",
    "\n",
    "# 1. Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "evaluate_model(\"Linear Regression\", y_test, lr_predictions)\n",
    "\n",
    "# # 2. Decision Tree Regressor\n",
    "# dt_model = DecisionTreeRegressor()\n",
    "# dt_model.fit(X_train, y_train)\n",
    "# dt_predictions = dt_model.predict(X_test)\n",
    "# evaluate_model(\"Decision Tree Regressor\", y_test, dt_predictions)\n",
    "\n",
    "# # 3. Random Forest Regressor\n",
    "# rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "# rf_predictions = rf_model.predict(X_test)\n",
    "# evaluate_model(\"Random Forest Regressor\", y_test, rf_predictions)\n",
    "\n",
    "# 4. XGBoost Regressor\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "evaluate_model(\"XGBoost Regressor\", y_test, xgb_predictions)\n",
    "\n",
    "# Feature Importance Analysis (for Random Forest and XGBoost)\n",
    "if hasattr(rf_model, 'feature_importances_'):\n",
    "    importances_rf = rf_model.feature_importances_\n",
    "    print(\"\\nFeature Importances (Random Forest):\")\n",
    "    for feature, importance in zip(X.columns, importances_rf):\n",
    "        print(f\"{feature}: {importance}\")\n",
    "\n",
    "if hasattr(xgb_model, 'feature_importances_'):\n",
    "    importances_xgb = xgb_model.feature_importances_\n",
    "    print(\"\\nFeature Importances (XGBoost):\")\n",
    "    for feature, importance in zip(X.columns, importances_xgb):\n",
    "        print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971510df-c141-4534-8eb3-1c1e9ec54ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_model(model_name, y_test, predictions):\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    print(f\"\\n{model_name} Evaluation Metrics:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"R² Score: {r2}\")\n",
    "\n",
    "# 1. Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(\"Linear Regression\", y_test, lr_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0589e930-c415-41cc-808e-59843dff6886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
